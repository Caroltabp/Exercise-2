{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b3f03edc2a07a39fe0afc229a42ff926",
     "grade": false,
     "grade_id": "cell-5077a9fd293c1c14",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Review module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "03a35065f6a4c6e3cbeb4028497dbb99",
     "grade": false,
     "grade_id": "cell-1d1fe56643ff2630",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "**Instructions**\n",
    "\n",
    "In order to complete this review module, we recommend you follow these instructions:\n",
    "\n",
    "1. Complete the functions provided to you in this notebook, but do **not** change the name of the function or the name(s) of the argument(s). If you do that, the autograder will fail and you will not receive any points.\n",
    "2. Run all the function-definition cells before you run the testing cells. The functions must exist before they are graded!\n",
    "3. Read the function docstrings carefully. They contain additional information about how the code should look (a [docstring](https://www.datacamp.com/community/tutorials/docstrings-python) is the stuff that comes between the triple quotes).\n",
    "4. Some functions may require several outputs (the docstrings tell you which ones). Make sure they are returned in the right order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Using cached matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 2)) (1.22.3)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 3)) (1.4.1)\n",
      "Collecting seaborn\n",
      "  Using cached seaborn-0.11.2-py3-none-any.whl (292 kB)\n",
      "Collecting statsmodels\n",
      "  Using cached statsmodels-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 7)) (7.7.0)\n",
      "Collecting lxml\n",
      "  Downloading lxml-4.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.9 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (7.22.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.5.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.1.3)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (1.1.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (5.0.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets->-r requirements.txt (line 7)) (3.6.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (6.1.12)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (49.6.0.post20210108)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (3.0.18)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (5.0.6)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.18.0)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.7.5)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (4.8.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (2.8.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (4.7.1)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (3.2.0)\n",
      "Requirement already satisfied: six>=1.11.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (20.3.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets->-r requirements.txt (line 7)) (0.17.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r requirements.txt (line 7)) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (6.3.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (20.1.0)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (22.0.3)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.9.4)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.5.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (6.0.7)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (2.11.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->-r requirements.txt (line 7)) (2.8.1)\n",
      "Collecting kiwisolver>=1.0.1\n",
      "  Using cached kiwisolver-1.4.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "Collecting pillow>=6.2.0\n",
      "  Using cached Pillow-9.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "Collecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Using cached fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (20.9)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->-r requirements.txt (line 1)) (2.4.7)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas->-r requirements.txt (line 3)) (2021.1)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Collecting patsy>=0.5.2\n",
      "  Using cached patsy-0.5.2-py2.py3-none-any.whl (233 kB)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.1.1)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.1.2)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.8.4)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.5.3)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.4.4)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r requirements.txt (line 7)) (0.5.1)\n",
      "Installing collected packages: packaging, pillow, kiwisolver, fonttools, cycler, threadpoolctl, scipy, patsy, matplotlib, joblib, statsmodels, seaborn, scikit-learn, lxml\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 20.9\n",
      "    Uninstalling packaging-20.9:\n",
      "      Successfully uninstalled packaging-20.9\n",
      "Successfully installed cycler-0.11.0 fonttools-4.33.3 joblib-1.1.0 kiwisolver-1.4.3 lxml-4.9.0 matplotlib-3.5.2 packaging-21.3 patsy-0.5.2 pillow-9.1.1 scikit-learn-1.1.1 scipy-1.8.1 seaborn-0.11.2 statsmodels-0.13.2 threadpoolctl-3.1.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a8683e032604423ff7bad0979b88befb",
     "grade": false,
     "grade_id": "cell-621bbf3c8c713af3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 1\n",
    "\n",
    "This is a dataset of college admissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9d6c7e7b246d82b6b215b2dd71888491",
     "grade": false,
     "grade_id": "cell-5c41c0245a87b6e6",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>admit</th>\n",
       "      <th>gre</th>\n",
       "      <th>gpa</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>380</td>\n",
       "      <td>3.61</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>660</td>\n",
       "      <td>3.67</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>800</td>\n",
       "      <td>4.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>640</td>\n",
       "      <td>3.19</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>520</td>\n",
       "      <td>2.93</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   admit  gre   gpa  rank\n",
       "0      0  380  3.61     3\n",
       "1      1  660  3.67     3\n",
       "2      1  800  4.00     1\n",
       "3      1  640  3.19     4\n",
       "4      0  520  2.93     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "\n",
    "df = pd.read_csv(\"data/data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "af74ac2a1e0b301f402bb77f739364f8",
     "grade": false,
     "grade_id": "cell-529877183a33b6f9",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create a logistic regression model that predicts `admit` from `gre`, `gpa`, and `rank` (`rank` measures the prestige of the institution - where 1 is the highest prestige ranking and 4 is the lowest prestige ranking). Don't forget to normalize `gre` and `gpa` by subtracting the mean and dividing by the standard deviation (call the new columns `gre_normalized`and `gpa_normalized`, respectively).\n",
    "\n",
    "**Hint:** Use `df[\"Intercept\"] = 1` to define the intercept that you have to pass to `statsmodels` to initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tst = df.copy()\n",
    "df_tst['gre_normalized'] = (df_tst['gre'] - df_tst['gre'].mean()) / df_tst['gre'].std()\n",
    "df_tst['gpa_normalized'] = (df_tst['gpa'] - df_tst['gpa'].mean()) / df_tst['gpa'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.574302\n",
      "         Iterations 5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>admit</td>      <th>  No. Observations:  </th>  <td>   400</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   396</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 18 Jun 2022</td> <th>  Pseudo R-squ.:     </th>  <td>0.08107</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>23:29:49</td>     <th>  Log-Likelihood:    </th> <td> -229.72</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -249.99</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>8.207e-09</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "         <td></td>           <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>      <td>    0.5326</td> <td>    0.315</td> <td>    1.689</td> <td> 0.091</td> <td>   -0.086</td> <td>    1.151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gre_normalized</th> <td>    0.2650</td> <td>    0.126</td> <td>    2.101</td> <td> 0.036</td> <td>    0.018</td> <td>    0.512</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gpa_normalized</th> <td>    0.2957</td> <td>    0.125</td> <td>    2.373</td> <td> 0.018</td> <td>    0.051</td> <td>    0.540</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rank</th>           <td>   -0.5600</td> <td>    0.127</td> <td>   -4.405</td> <td> 0.000</td> <td>   -0.809</td> <td>   -0.311</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:                  admit   No. Observations:                  400\n",
       "Model:                          Logit   Df Residuals:                      396\n",
       "Method:                           MLE   Df Model:                            3\n",
       "Date:                Sat, 18 Jun 2022   Pseudo R-squ.:                 0.08107\n",
       "Time:                        23:29:49   Log-Likelihood:                -229.72\n",
       "converged:                       True   LL-Null:                       -249.99\n",
       "Covariance Type:            nonrobust   LLR p-value:                 8.207e-09\n",
       "==================================================================================\n",
       "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------\n",
       "Intercept          0.5326      0.315      1.689      0.091      -0.086       1.151\n",
       "gre_normalized     0.2650      0.126      2.101      0.036       0.018       0.512\n",
       "gpa_normalized     0.2957      0.125      2.373      0.018       0.051       0.540\n",
       "rank              -0.5600      0.127     -4.405      0.000      -0.809      -0.311\n",
       "==================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tst['Intercept'] = 1\n",
    "\n",
    "model_tst = sm.Logit(df_tst['admit'], df_tst[['Intercept', 'gre_normalized', 'gpa_normalized', 'rank']])\n",
    "model_res_tst = model_tst.fit()\n",
    "model_res_tst.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "c36541dd1aab6304f68b6be522dff864",
     "grade": false,
     "grade_id": "cell-20b276b659dd69ac",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fit_logistic_regression():\n",
    "    \"\"\"\n",
    "    Create a logistic regression model\n",
    "    and fit it to `df`. The model predicts\n",
    "    `admit` from `gre`, `gpa`, and `rank`, and\n",
    "    outputs `model_res`, which results from\n",
    "    fitting the model to the dataset using the\n",
    "    `.fit()` method.    \n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    df['gpa_normalized'] = (df['gpa'] - df['gpa'].mean()) / df['gpa'].std()\n",
    "    df['gre_normalized'] = (df['gre'] - df['gre'].mean()) / df['gre'].std()\n",
    "    df['Intercept'] = 1\n",
    "\n",
    "    model = sm.Logit(df['admit'], df[['Intercept', 'gre_normalized', 'gpa_normalized', 'rank']])\n",
    "    \n",
    "    model_res = model.fit(disp=False) # We use disp=False to turn off verbosity\n",
    "    return model_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "b18b820a83e3d1b1b5b64d88fadd8bbf",
     "grade": false,
     "grade_id": "cell-8c448cb067cd94dc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 2\n",
    "\n",
    "Use the `roc_curve` function from `sklearn` to calculate the ROC curve for the model you have just created. The function `calculate_roc()` as such should not plot the curve, but rather calculate its coordinates. We have provided you with additional code as a convenience to help check that your ROC looks correct. That plotting code is not part of your assignment, so it is not required that you modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "6feeb3db49f3e056b9d1238aed771419",
     "grade": false,
     "grade_id": "cell-74030a045d191d19",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def calculate_roc(model_res):\n",
    "    \"\"\"\n",
    "    Calculates the ROC curve for the logistic regression\n",
    "    defined in the `fit_logistic_regression()` function\n",
    "    \n",
    "    Arguments:\n",
    "    `model_res`: This is the output of the \n",
    "    `fit_logistic_regression()` function\n",
    "    \n",
    "    Output:\n",
    "    `roc_p`: A tuple of numpy arrays generated by the\n",
    "    `roc_curve()` function from sklearn.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    predict_p = model_res.predict(df[['Intercept', 'gre_normalized', 'gpa_normalized', 'rank']])\n",
    "    roc_p = roc_curve(df['admit'], predict_p)\n",
    "    return roc_p\n",
    "\n",
    "    \n",
    "# The code below is to help you visualize your curve - No need to modify it\n",
    "model_res = fit_logistic_regression()\n",
    "roc_p = calculate_roc(model_res)\n",
    "plt.figure()\n",
    "line_width = 2\n",
    "plt.plot(roc_p[0], roc_p[1], color='darkorange', lw=line_width, label=f'ROC curve')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=line_width, linestyle='--', label='Random guess')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Classification of admitted / not admitted')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "71532f4e16a7c6816f3ef460ab177f0c",
     "grade": false,
     "grade_id": "cell-d49a4751fe533e10",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Exercise 3\n",
    "\n",
    "\n",
    "Complete the function below to classify applicants depending on `gre`, `gpa` and `rank`. It should take a cut-off probability $p$ and classify applicants following this decision tree:\n",
    "\n",
    "~~~plain\n",
    "If predicted value is less than c, then classify as not admitted.\n",
    "Classify as admitted otherwise.\n",
    "~~~\n",
    "\n",
    "Where $c$ is the cut-off value of your logistic regression.\n",
    "\n",
    "**Hints:**\n",
    "* Remember that your cut-off value $c$ is not the same as your cut-off probability $p$. $c$ is the log-odds of $p$ (you can use the `log` function from `numpy` to help you compute $c$).\n",
    "* Notice also that your function must return an object of type `bool`.\n",
    "* The function takes as inputs `gre` and `gpa` in their normalized versions, that is, after you've subtracted their means and divided by the respective standard deviations. You don't really need to doing anything about this, because the model you created in exercise 1 already uses normalized variables.\n",
    "* We provided you with some code to help you check your results. You don't need to modify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a51e0fb1eb571dca73e2c15dbe382c36",
     "grade": false,
     "grade_id": "cell-8803a0ce347c8810",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gre_normalized</th>\n",
       "      <th>gpa_normalized</th>\n",
       "      <th>rank</th>\n",
       "      <th>admitted_p_0.1</th>\n",
       "      <th>admitted_p_0.5</th>\n",
       "      <th>admitted_p_0.9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.972155</td>\n",
       "      <td>0.341859</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>-0.759199</td>\n",
       "      <td>0.368135</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>0.625884</td>\n",
       "      <td>0.525795</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>-0.759199</td>\n",
       "      <td>0.473242</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>0.972155</td>\n",
       "      <td>0.683454</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.972155</td>\n",
       "      <td>-1.287291</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.106478</td>\n",
       "      <td>-1.497503</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>-1.451740</td>\n",
       "      <td>1.392922</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.106478</td>\n",
       "      <td>0.630901</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.625884</td>\n",
       "      <td>-0.131120</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>-2.490553</td>\n",
       "      <td>-1.444950</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>-0.412928</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>-1.105469</td>\n",
       "      <td>0.998773</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>-0.586063</td>\n",
       "      <td>-0.761759</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>-3.183094</td>\n",
       "      <td>-1.471227</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0.279614</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.279614</td>\n",
       "      <td>-0.577822</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>-0.066657</td>\n",
       "      <td>0.184199</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>-0.066657</td>\n",
       "      <td>-0.709205</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>1.837832</td>\n",
       "      <td>1.366646</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     gre_normalized  gpa_normalized  rank  admitted_p_0.1  admitted_p_0.5  \\\n",
       "141        0.972155        0.341859     4            True           False   \n",
       "174       -0.759199        0.368135     4            True           False   \n",
       "331        0.625884        0.525795     3            True           False   \n",
       "135       -0.759199        0.473242     3            True           False   \n",
       "398        0.972155        0.683454     2            True           False   \n",
       "80         0.972155       -1.287291     4            True           False   \n",
       "22         0.106478       -1.497503     4            True           False   \n",
       "203       -1.451740        1.392922     4            True           False   \n",
       "198        0.106478        0.630901     3            True           False   \n",
       "54         0.625884       -0.131120     3            True           False   \n",
       "315       -2.490553       -1.444950     2            True           False   \n",
       "370       -0.412928        0.998773     2            True           False   \n",
       "276       -1.105469        0.998773     3            True           False   \n",
       "283       -0.586063       -0.761759     4            True           False   \n",
       "304       -3.183094       -1.471227     3           False           False   \n",
       "337        0.279614       -0.788035     4            True           False   \n",
       "130        0.279614       -0.577822     2            True           False   \n",
       "153       -0.066657        0.184199     3            True           False   \n",
       "352       -0.066657       -0.709205     3            True           False   \n",
       "245        1.837832        1.366646     3            True           False   \n",
       "\n",
       "     admitted_p_0.9  \n",
       "141           False  \n",
       "174           False  \n",
       "331           False  \n",
       "135           False  \n",
       "398           False  \n",
       "80            False  \n",
       "22            False  \n",
       "203           False  \n",
       "198           False  \n",
       "54            False  \n",
       "315           False  \n",
       "370           False  \n",
       "276           False  \n",
       "283           False  \n",
       "304           False  \n",
       "337           False  \n",
       "130           False  \n",
       "153           False  \n",
       "352           False  \n",
       "245           False  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def classify(p, gre_norm, gpa_norm, rank):\n",
    "    \"\"\"\n",
    "    Classify an applicant as admitted or not admitted\n",
    "    depending on their gre, gpa and rank.\n",
    "    \n",
    "    Arguments:\n",
    "    `p`: The cut-off probability\n",
    "    `gre_norm`: The applicant's GRE, normalized.\n",
    "    `gpa_norm`: The applicant's GPA, normalized.\n",
    "    `rank`: The rank of the institution.\n",
    "    \n",
    "    Outputs:\n",
    "    A boolean that is True if admitted, and False if not admitted.\n",
    "    \"\"\"\n",
    "\n",
    "    l = fit_logistic_regression().params\n",
    "    intercept, coef_gre, coef_gpa, coef_rank = l[0], l[1], l[2], l[3]\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    return (intercept + coef_gre*gre_norm + coef_gpa*gpa_norm + coef_rank*rank) >= np.log(p/(1-p))\n",
    "\n",
    "\n",
    "# The code below is to help you check your results - No need to modify it\n",
    "class_as_admitted = []\n",
    "res = df[[\"gre_normalized\", \"gpa_normalized\", \"rank\"]].sample(20)\n",
    "for p in [0.1, 0.5, 0.9]:\n",
    "    res[\"admitted_p_\" + str(p)] = res[[\"gre_normalized\", \"gpa_normalized\", \"rank\"]].apply(lambda x: classify(p, x[0], x[1], x[2]), axis=1)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Intercept         0.532610\n",
       "gre_normalized    0.264990\n",
       "gpa_normalized    0.295706\n",
       "rank             -0.560031\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_logistic_regression().params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.532610+0.264990*(0.799020)+0.295706*(-0.735482)-0.560031*(2)>=np.log(0.9/(1-0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d7a4bf3aab28632b79ffdbd8bc768249",
     "grade": false,
     "grade_id": "cell-d83935fb5c7cedec",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Testing Cells\n",
    "\n",
    "Run the below cells to check your answers. Make sure you run your solution cells first before running the cells below, otherwise you will get a `NameError` when checking your answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "68e0635832269a8023b5bad62acdf235",
     "grade": true,
     "grade_id": "cell-ed44f7a61b0c9a8f",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 1 looks correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 1 (one point)\n",
    "s = fit_logistic_regression().summary().tables[1].as_html()\n",
    "sdf = pd.read_html(s,header=0,index_col=0)[0][[\"coef\", \"P>|z|\"]]\n",
    "co = list(sdf[\"coef\"])\n",
    "pr = list(sdf[\"P>|z|\"])\n",
    "assert 0.2957 in co, \"Ex. 1 - For some reason, you obtained the wrong coefficient for gpa. Did you normalize the variables, created an Intercept and used the Logit function from statmodels? Check out the main case if you need to brush up!\"\n",
    "assert 0.2650 in co, \"Ex. 1 - For some reason, you obtained the wrong coefficient for gre. Did you normalize the variables, created an Intercept and used the Logit function from statmodels? Check out the main case if you need to brush up!\"\n",
    "assert -0.5600 in co, \"Ex. 1 - For some reason, you obtained the wrong coefficient for rank. Did you normalize the variables, created an Intercept and used the Logit function from statmodels? Check out the main case if you need to brush up!\"\n",
    "assert sum(sdf[\"P>|z|\"] > 0.05) == 1, \"Ex. 1 - For some reason, you obtained a wrong p-value for one or more of your explanatory variables. Did you normalize the variables, created an Intercept and used the Logit function from statmodels? Check out the main case if you need to brush up!\"\n",
    "print(\"Exercise 1 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4811dc9fa693f96cbce94944c6fa8970",
     "grade": true,
     "grade_id": "cell-2bdc0be15e752b81",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 2 looks correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 2 (one point)\n",
    "from sklearn.metrics import auc\n",
    "model_res = fit_logistic_regression()\n",
    "roc_p = calculate_roc(model_res)\n",
    "assert -0.01 < (auc( roc_p[0], roc_p[1] ) - 0.6921202157422629) < 0.01 , \"Ex. 2 - We tried calculating your ROC's AUC, but it seems the numbers don't match! Please refer to the main case, section 'The Receiver Operating Characteristic (ROC) curve', to see how to compute a ROC curve.\"\n",
    "print(\"Exercise 2 looks correct!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93a7cc8e8a88aae5ef1fed1e98dba3d2",
     "grade": true,
     "grade_id": "cell-ed00659728b6ef6e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercise 3 looks correct!\n"
     ]
    }
   ],
   "source": [
    "# Ex. 3 (one point)\n",
    "class_as_admitted = []\n",
    "for p in [0.1, 0.5, 0.9]:\n",
    "    res = df[[\"gre_normalized\", \"gpa_normalized\", \"rank\"]].apply(lambda x: classify(p, x[0], x[1], x[2]), axis=1)\n",
    "    class_as_admitted.append(res.sum())\n",
    "\n",
    "assert class_as_admitted == [385, 49, 0], \"Ex. 3 - When we apply your function to the dataset, we get some unexpected results. Remember that a logistic regression is just logodds(p) = estimated_intercept + b1*v1 + ... + bn*vn where vn is variable n and bn its corresponding coefficient. Check out the main case for more information.\"\n",
    "print(\"Exercise 3 looks correct!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribution\n",
    "\n",
    "\"binary.csv\" (dataset), Dec 16, 2013, UCLA Institute for Digital Research and Education - Statistical Consulting, [UCLA Statistical Consulting license](https://stats.idre.ucla.edu/ucla/about/), https://stats.idre.ucla.edu/r/dae/logit-regression/"
   ]
  }
 ],
 "metadata": {
  "c1_recart": "7.28.0-57c20131aabc1dc2a8c675852d80a7da",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
